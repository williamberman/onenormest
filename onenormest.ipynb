{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b53ed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax import lax, vmap, jit\n",
    "import jax.numpy as jnp\n",
    "from functools import partial\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da363683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onenormest(key, A, t, itmax):\n",
    "    \"\"\"\n",
    "    https://github.com/gnu-octave/octave/blob/eff42b5a8c617f62a0ee1ddc2b70c246bbf32cb3/scripts/linear-algebra/normest1.m\n",
    "    https://github.com/scipy/scipy/blob/59dac8a9fa9ea856f4a50521d295a3497d648faa/scipy/sparse/linalg/_onenormest.py\n",
    "    http://eprints.maths.manchester.ac.uk/321/1/35608.pdf\n",
    "    \"\"\"\n",
    "    # TODO add type and shape checking\n",
    "    return _onenormest(key, A, t, itmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f36ab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _OnenormestLoopState(NamedTuple):\n",
    "    # Number of loop iterations (starts at 1)\n",
    "    k: int\n",
    "    \n",
    "    # Flag to indicate break out of loop. We can't directly break out of the\n",
    "    # loop because jax requires us to return a value from the loop body that\n",
    "    # is then checked in the cond fun.\n",
    "    break_flag: bool\n",
    "        \n",
    "    # \"ind_hist = [ ] % Integer vector recording indices of used unit vectors e_j\"\n",
    "    #\n",
    "    # row vector of size n+1 (should be size n but additional value is to allow for sentinel values in ind). \n",
    "    # ind_hist[j] == 0 if e_j has not been used\n",
    "    # ind_hist[j] == 1 if e_j has been used  \n",
    "    #\n",
    "    # in the scipy implementation and Higham, this is a growable array that stores\n",
    "    # indices of the unit vectors. In the octave implementation, this is a fixed\n",
    "    # sized array that writes 1 into index j when e_j is used.\n",
    "    # We use the fixed sized array so we can jit compile the function.\n",
    "    ind_hist: jnp.ndarray\n",
    "        \n",
    "    # The previous estimate of the one norm\n",
    "    est_old: float\n",
    "        \n",
    "    # The current estimate of the one norm\n",
    "    est: float\n",
    "    \n",
    "    # ind is a row vector of shape (t,)\n",
    "    #\n",
    "    # ind tracks which elementary vectors are stored in the column vectors of\n",
    "    # x. i.e. e_{ind[j]} = X[:, j]\n",
    "    # \n",
    "    # ind is shape (n,) in Higham but only the first t values\n",
    "    # are read out of it. The first t values are read for writing to ind_hist.\n",
    "    # It is also read out of with column indices of Y and Y is shape (n, t).\n",
    "    #\n",
    "    # because we only test elementary vectors a single time, it is not guaranteed\n",
    "    # we'll have t elementary vectors to test on each loop. We handle this by filling\n",
    "    # non-used elements of ind with a sentinel value \"n\". This sentinel value requires\n",
    "    # extending ind_hist's size by one to n+1\n",
    "    ind: jnp.ndarray\n",
    "        \n",
    "    # TODO\n",
    "    S: jnp.ndarray\n",
    "        \n",
    "    # TODO\n",
    "    X: jnp.ndarray\n",
    "        \n",
    "    nresamples: int\n",
    "    \n",
    "    nmults: int\n",
    "        \n",
    "    # The column of Y that produces the best estimate for the 1 norm of A\n",
    "    # as a row vector (n,)\n",
    "    w: jnp.ndarray\n",
    "        \n",
    "    # v == The unit vector e_{ind_best}\n",
    "    ind_best: int\n",
    "        \n",
    "    # key for resampling\n",
    "    key: jax.random.PRNGKey\n",
    "        \n",
    "\n",
    "@partial(jit, static_argnums=[2])\n",
    "def _onenormest(key, A, t, itmax):\n",
    "    AT = A.T\n",
    "    n = A.shape[0]\n",
    "    key, subkey = jax.random.split(key)\n",
    "    X, nresamples = _onenormest_build_starting_matrix(subkey, n, t)\n",
    "    \n",
    "    nmults = 0\n",
    "    \n",
    "    # size is set to n+1 so ind can write to its sentintel empty value of n \n",
    "    ind_hist = jnp.zeros((n+1,))\n",
    "    \n",
    "    est_old = float(0)\n",
    "    \n",
    "    est = float(0)\n",
    "    \n",
    "    ind = jnp.zeros((t,), dtype=int)\n",
    "    \n",
    "    S = jnp.zeros((n, t))\n",
    "    \n",
    "    w = jnp.zeros((n,))\n",
    "    \n",
    "    ind_best = 0\n",
    "    \n",
    "    k = 1\n",
    "    \n",
    "    init_loop_state = _OnenormestLoopState(\n",
    "        k=k,\n",
    "        break_flag=False,\n",
    "        ind_hist=ind_hist,   \n",
    "        est_old=est_old,\n",
    "        est=est,\n",
    "        ind=ind,\n",
    "        S=S,\n",
    "        X=X,\n",
    "        nmults=nmults,\n",
    "        nresamples=nresamples,\n",
    "        w=w,\n",
    "        ind_best=ind_best,\n",
    "        key=key\n",
    "    )\n",
    "    \n",
    "    # Continue while the break flag has not been set\n",
    "    def cond_fun(loop_state: _OnenormestLoopState) -> bool:\n",
    "        return jnp.logical_not(loop_state.break_flag)\n",
    "    \n",
    "    def body_fun(loop_state: _OnenormestLoopState) -> _OnenormestLoopState:\n",
    "        k = loop_state.k\n",
    "        ind_hist = loop_state.ind_hist\n",
    "        est_old = loop_state.est_old\n",
    "        est = loop_state.est\n",
    "        ind = loop_state.ind\n",
    "        S = loop_state.S\n",
    "        X = loop_state.X\n",
    "        nmults = loop_state.nmults\n",
    "        nresamples = loop_state.nresamples\n",
    "        w = loop_state.w\n",
    "        ind_best = loop_state.ind_best\n",
    "        key = loop_state.key\n",
    "        \n",
    "        Y = A @ X\n",
    "        nmults += 1\n",
    "        \n",
    "        # \"est = max{ ||Y (: , j)||_1 : j = 1:t }\"\n",
    "        # The estimate is the max 1 norm of the column vectors of Y\n",
    "        potential_estimates = jnp.sum(jnp.abs(Y), axis=0)\n",
    "        # The column in Y of the best esimate\n",
    "        best_j = jnp.argmax(potential_estimates)\n",
    "        est = potential_estimates[best_j]\n",
    "        \n",
    "        # if est > est_old or k = 2\n",
    "        #     ind_best = ind_j where est = |Y (: , j)|_1\n",
    "        #     w = Y(: , ind best)\n",
    "        # end\n",
    "        w = lax.cond(\n",
    "            jnp.logical_or(est > est_old, k == 2), \n",
    "            lambda: Y[:, best_j], \n",
    "            lambda: w\n",
    "        )\n",
    "        # TODO(will)\n",
    "        # Note the additional k >= 2 in the condition. This comes from scipy. \n",
    "        # Not sure why it's there\n",
    "        ind_best = lax.cond(\n",
    "            jnp.logical_and(jnp.logical_or(est > est_old, k == 2), k >= 2), \n",
    "            lambda: ind[best_j], \n",
    "            lambda: ind_best\n",
    "        )\n",
    "        \n",
    "        est = lax.cond(\n",
    "            jnp.logical_and(k >= 2, est <= est_old),\n",
    "            lambda: est_old,\n",
    "            lambda: est,\n",
    "        )\n",
    "        \n",
    "        def cont1():\n",
    "            est_old = est\n",
    "            S_old = S\n",
    "            \n",
    "            def cont2():\n",
    "                S = sign_round_up(Y)\n",
    "                \n",
    "                def cont3():\n",
    "                    def resample_S_helper():\n",
    "                        key_, subkey = jax.random.split(key)\n",
    "                        S_, inc_nresamples = resample_S(subkey, S, S_old, n, t)\n",
    "                        return S_, inc_nresamples, key_\n",
    "                    \n",
    "                    S_, inc_nresamples, key_ = lax.cond(t > 1, resample_S_helper, lambda: (S, 0, key))\n",
    "                    nresamples_ = nresamples + inc_nresamples\n",
    "                    \n",
    "                    Z = AT @ S_\n",
    "                    nmults_ = nmults + 1\n",
    "                    \n",
    "                    # \"h_i = |Z(i, :)|∞, ind_i = i, i = 1:n\"\n",
    "                    # h is the max norms of the row vectors of Z\n",
    "                    # ind will end up being the indices of h in sorted descending order\n",
    "                    # we can just set ind after we argsort h\n",
    "                    h = jnp.linalg.norm(Z, ord=jnp.inf, axis=1)\n",
    "                    \n",
    "                    def cont4():\n",
    "                        # \"Sort h so that h1 ≥···≥ hn and re-order ind correspondingly\"\n",
    "                        # We don't actually need to sort h because we only need its indices\n",
    "                        # ind_tmp is ind before it's sorted and capped to size t\n",
    "                        ind_tmp = jnp.argsort(h)[::-1]\n",
    "                        \n",
    "                        def cont5():\n",
    "                            ind = lax.cond(\n",
    "                                t > 1, \n",
    "                                lambda: ind_not_in_ind_hist(ind_tmp, ind_hist, n, t),\n",
    "                                # hist is empty so we don't have to check hist, but we\n",
    "                                # do have to take the first t elements of ind_tmp\n",
    "                                lambda: ind_tmp[:t]\n",
    "                            )\n",
    "                            \n",
    "                            # \"X(: , j) = e_{ind[j]} , j = 1:t\"\n",
    "                            #\n",
    "                            # Set the first t column vectors of X to the elementary\n",
    "                            # vectors with the dimension specified in ind\n",
    "                            #\n",
    "                            # Since X has t columns, we can just set a new X\n",
    "                            # instead of writing into the old one. \n",
    "                            #\n",
    "                            # Note that it's ok for ind to contain the sentinel n\n",
    "                            # because `elementary_vector`\n",
    "                            # will return a zero vector instead of an elementary vector.\n",
    "                            # This will cause X to have zero vectors which is ok because the\n",
    "                            # zero vectors will cause norm estimations of 0 which are always\n",
    "                            # a correct underestimate of the one norm.\n",
    "                            X = elementary_vectors_with_lookup(n, jnp.arange(t), ind)\n",
    "                            \n",
    "                            # \"ind_hist = [ind_hist ind(1:t)]\"\n",
    "                            # Note that we cannot concatenate to ind_hist because our ind_hist is\n",
    "                            # a fixed size where we set flags at indices for used unit vectors\n",
    "                            ind_hist_ = ind_hist.at[ind].set(1)\n",
    "                            \n",
    "                            return _OnenormestLoopState(break_flag=False, k=k, ind_hist=ind_hist_, est_old=est_old, est=est, ind=ind, S=S_, X=X, nmults=nmults_, nresamples=nresamples_, w=w, ind_best=ind_best, key=key_)\n",
    "                        \n",
    "                        \n",
    "                        return lax.cond(\n",
    "                            jnp.logical_and(t > 1, check_ind_in_ind_hist(ind_tmp, ind_hist, t)),\n",
    "                            lambda: _OnenormestLoopState(break_flag=True, k=k, ind_hist=ind_hist, est_old=est_old, est=est, ind=ind, S=S_, X=X, nmults=nmults_, nresamples=nresamples_, w=w, ind_best=ind_best, key=key_),\n",
    "                            cont5\n",
    "                            \n",
    "                        )\n",
    "\n",
    "                    \n",
    "                    # \"if k ≥ 2 and max(h_i)) = h_{ind_best}\n",
    "                    #     goto (6) (break)\n",
    "                    # end\"\n",
    "                    return lax.cond(\n",
    "                        jnp.logical_and(k >= 2, jnp.max(h) == h[ind_best]),\n",
    "                        lambda: _OnenormestLoopState(break_flag=True, k=k, ind_hist=ind_hist, est_old=est_old, est=est, ind=ind, S=S_, X=X, nmults=nmults_, nresamples=nresamples_, w=w, ind_best=ind_best, key=key_),\n",
    "                        cont4\n",
    "                    )\n",
    "                                        \n",
    "                # If every column of S is parallel to a column of S_old, \n",
    "                #     goto (6) (break)\n",
    "                # end\n",
    "                return lax.cond(\n",
    "                    every_col_of_X_is_parallel_to_a_col_of_Y(S, S_old, n),\n",
    "                    lambda: _OnenormestLoopState(break_flag=True, k=k, ind_hist=ind_hist, est_old=est_old, est=est, ind=ind, S=S, X=X, nmults=nmults, nresamples=nresamples, w=w, ind_best=ind_best, key=key),\n",
    "                    cont3\n",
    "                )\n",
    "            \n",
    "            return lax.cond(\n",
    "                k > itmax,\n",
    "                lambda: _OnenormestLoopState(break_flag=True, k=k, ind_hist=ind_hist, est_old=est_old, est=est, ind=ind, S=S, X=X, nmults=nmults, nresamples=nresamples, w=w, ind_best=ind_best, key=key),\n",
    "                cont2\n",
    "            )\n",
    "        \n",
    "        return lax.cond(\n",
    "            jnp.logical_and(k >= 2, est <= est_old),\n",
    "            lambda: _OnenormestLoopState(break_flag=True, k=k, ind_hist=ind_hist, est_old=est_old, est=est, ind=ind, S=S, X=X, nmults=nmults, nresamples=nresamples, w=w, ind_best=ind_best, key=key),\n",
    "            cont1\n",
    "        )\n",
    "                \n",
    "    \n",
    "    final_loop_state = lax.while_loop(\n",
    "        cond_fun,\n",
    "        body_fun,\n",
    "        init_loop_state\n",
    "    )\n",
    "    \n",
    "    est = final_loop_state.est\n",
    "    ind_best = final_loop_state.ind_best\n",
    "    w = final_loop_state.w\n",
    "    nmults = final_loop_state.nmults\n",
    "    nresamples = final_loop_state.nresamples\n",
    "    \n",
    "    v = elementary_vector(n, ind_best)\n",
    "    return est, v, w, nmults, nresamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad68f38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _onenormest_build_starting_matrix(key, n, t):\n",
    "    \"\"\"\n",
    "    \"Choose starting matrix X ∈ Rn×t with columns of unit 1-norm.\"\n",
    "    \n",
    "    \"We now explain our choice of starting matrix. We take the first column of X to\n",
    "    be the vector of 1s, which is the starting vector used in Algorithm 2.1. This has the\n",
    "    advantage that for a matrix with nonnegative elements the algorithm converges with\n",
    "    an exact estimate on the second iteration, and such matrices arise in applications,\n",
    "    for example as a stochastic matrix or as the inverse of an M-matrix. The remaining\n",
    "    columns are chosen as rand{−1, 1}, with a check for and correction of parallel columns,\n",
    "    exactly as for S in the body of the algorithm.\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initializing the matrix to all zeroes is important for the parallel checks\n",
    "    # that will be done during resampling\n",
    "    X = jnp.zeros((n, t))\n",
    "    \n",
    "    # \"We take the first column of X to be the vector of 1s\"\n",
    "    X = X.at[:,0].set(jnp.ones((n,), dtype=float))\n",
    "    \n",
    "    # NOTE(will) - We could alternatively sample all columns of the matrix at once up front.\n",
    "    # We could still do a parallel check by dot producting the individual column against\n",
    "    # the matrix and checking there is only a single column (itself) that it is parallel\n",
    "    # with. Since we would still have to loop over the columns of the matrix to do the check, \n",
    "    # I'm assuming that sampling one at a time in the loop is more efficient.\n",
    "    \n",
    "    # \"The remaining columns are chosen as rand{−1, 1}\"\"\n",
    "    # 1 key for re-sampling parallel columns\n",
    "    # t-1 subkeys for sampling the remaining column vectors\n",
    "    \n",
    "    # \"with a check for and correction of parallel columns, exactly as for S in the body of the algorithm\"\n",
    "    def sample_body_fun(i, args):\n",
    "        key, X, nresamples = args\n",
    "        \n",
    "        def resample_while_loop_body_fun(args):\n",
    "            key, v, nresamples = args\n",
    "            \n",
    "            key, subkey = jax.random.split(key)\n",
    "            v = _onenormest_sample_row(subkey, n)\n",
    "            nresamples += 1\n",
    "            \n",
    "            return key, v, nresamples\n",
    "            \n",
    "        key, subkey = jax.random.split(key)\n",
    "        starting_vector = _onenormest_sample_row(subkey, n)\n",
    "        \n",
    "        key, orthogonal_v, nresamples = lax.while_loop(\n",
    "            lambda args: _onenormest_X_needs_resampling(n, X, args[1]), # args[1] is current vector\n",
    "            resample_while_loop_body_fun,\n",
    "            (key, starting_vector, nresamples)\n",
    "        )\n",
    "        \n",
    "        X = X.at[:,i].set(orthogonal_v)\n",
    "        \n",
    "        return key, X, nresamples\n",
    "    \n",
    "    \n",
    "    (_key, X, nresamples) = lax.fori_loop(\n",
    "        # Start at column index 1. column i is checked if parallel against column's [0, i)\n",
    "        # so there are no prior columns to check column 0 against.\n",
    "        1,\n",
    "        t,\n",
    "        sample_body_fun,\n",
    "        # key for resampling, X, nresamples\n",
    "        (key, X, 0)\n",
    "    )\n",
    "    \n",
    "    # \"columns of unit 1-norm\"\n",
    "    X = X / float(n)\n",
    "    \n",
    "    return X, nresamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e596d093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _onenormest_sample_row(key, n):\n",
    "    \"\"\"\n",
    "    random row vector of size n of {-1, 1}s\n",
    "    \"\"\"\n",
    "    return jax.random.randint(key, minval=0, maxval=2, shape=(n,))*2 - 1\n",
    "\n",
    "# Sample column vectors instead of single row vector\n",
    "_onenormest_sample_col_vectors = vmap(_onenormest_sample_row, in_axes=(0, None), out_axes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e797c1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _onenormest_X_needs_resampling(n, X, v):\n",
    "    # v needs resampling if it is parallel to any column of X.\n",
    "    #\n",
    "    # All not sampled columns of X are zero and will not be parallel\n",
    "    # with v\n",
    "    #\n",
    "    # v is a row vector so we take a vector-matrix product to dot product\n",
    "    # v with all columns of X\n",
    "    #\n",
    "    # SciPy implementation:\n",
    "    # \"Columns are considered parallel when they are equal or negative.\n",
    "    # Entries are required to be in {-1, 1},\n",
    "    # which guarantees that the magnitudes of the vectors are identical.\"\n",
    "    return jnp.any(v @ X == n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d338d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE(will) - taken from scipy -- How to attribute?\n",
    "def sign_round_up(X):\n",
    "    \"\"\"\n",
    "    This should do the right thing for both real and complex matrices.\n",
    "    From Higham and Tisseur:\n",
    "    \"Everything in this section remains valid for complex matrices\n",
    "    provided that sign(A) is redefined as the matrix (aij / |aij|)\n",
    "    (and sign(0) = 1) transposes are replaced by conjugate transposes.\"\n",
    "    \"\"\"\n",
    "    X = jnp.where(X != 0, X, jnp.ones_like(X))\n",
    "    X = X / jnp.abs(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da2cdc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def every_col_of_X_is_parallel_to_a_col_of_Y(X, Y, n):\n",
    "    # A Y.T @ X \n",
    "    # if any of (Y.T @ X)[:, i] == n, then X[:, i] is parallel to a col in Y\n",
    "    \n",
    "    # Z[:, i] is the dot product of X[:, i] with Y's col vectors\n",
    "    Z = Y.T @ X\n",
    "    \n",
    "    # Using the same `== n` check as in _onenormest_X_needs_resampling,\n",
    "    # if any of Z[:, i] == n, then X[:, i] is parallel to at least one\n",
    "    # of Y's column vectors\n",
    "    X_parallel_column_vectors = jnp.any(Z == n, axis=0)\n",
    "    \n",
    "    every_col_is_parallel = jnp.all(X_parallel_column_vectors)\n",
    "    \n",
    "    return every_col_is_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ade0ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_S(key, S, S_old, n, t) -> (jnp.ndarray, int):\n",
    "    \"\"\"\n",
    "    \"Ensure that no column of S is parallel to another column of S\n",
    "    or to a column of S_old by replacing columns of S by rand{−1, 1}.\"\n",
    "    \"\"\"\n",
    "    def sample_body_fun(i, args):\n",
    "        key, S, nresamples = args\n",
    "        \n",
    "        def resample_while_loop_cond_fun(args):\n",
    "            _key, S, _nresamples = args\n",
    "            v = S[:, i]\n",
    "            return S_needs_resampling(v, S, S_old, n)\n",
    "        \n",
    "        def resample_while_loop_body_fun(args):\n",
    "            key, S, nresamples = args\n",
    "            \n",
    "            key, subkey = jax.random.split(key)\n",
    "            v = _onenormest_sample_row(subkey, n)\n",
    "            S = S.at[:, i].set(v)\n",
    "            nresamples += 1\n",
    "            \n",
    "            return key, S, nresamples\n",
    "        \n",
    "        key, S, nresamples = lax.while_loop(\n",
    "            resample_while_loop_cond_fun,\n",
    "            resample_while_loop_body_fun,\n",
    "            (key, S, nresamples)\n",
    "        )\n",
    "        \n",
    "        return key, S, nresamples\n",
    "        \n",
    "        \n",
    "    _key, S, nresamples = lax.fori_loop(\n",
    "        0,\n",
    "        t,\n",
    "        sample_body_fun,\n",
    "        # key for resampling, S, nresamples\n",
    "        (key, S, 0)\n",
    "    )\n",
    "    \n",
    "    return S, nresamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcdfff9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def S_needs_resampling(v, S, S_old, n):\n",
    "    \"\"\"\n",
    "    v is a column vector of S\n",
    "    v must be parallel to no columns in S or S_old\n",
    "    v will be parallel to itself which is in S, so we ensure there\n",
    "    is a single parallel vector in S\n",
    "    \n",
    "    we use the same `== n` check as in _onenormest_X_needs_resampling\n",
    "    \"\"\"\n",
    "    S_parallel_columns = (S.T @ v) == n\n",
    "    num_S_parallel = jnp.count_nonzero(S_parallel_columns)\n",
    "    # num_S_parallel can't be zero\n",
    "    some_S_parallel = num_S_parallel != 1\n",
    "    \n",
    "    \n",
    "    S_old_parallel_columns = (S_old.T @ v) == n\n",
    "    some_S_old_parallel = jnp.any(S_old_parallel_columns)\n",
    "    \n",
    "    return jnp.logical_or(some_S_parallel, some_S_old_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bc66c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"If ind(1:t) is contained in ind_hist\n",
    "#     goto (6) (break)\n",
    "# end\"\n",
    "def check_ind_in_ind_hist(ind_tmp, ind_hist, t):\n",
    "    ind_t = ind_tmp[0:t]\n",
    "    mask =  ind_hist[ind_t] == 1\n",
    "    return jnp.all(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d4b5715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ind_not_in_ind_hist(ind_tmp, ind_hist, n, t):\n",
    "    \"\"\"\n",
    "    \"Replace ind(1:t) by the first t indices in ind(1: n) that are\n",
    "    not in ind_hist.\"\n",
    "    \"\"\"\n",
    "    ind_not_in_hist = ind_hist[ind_tmp] == 0\n",
    "    \n",
    "    # n is used as sentinel for when ind's size should be smaller than t\n",
    "    # The sentinel value will set a zero vector in X\n",
    "    sentinels = jnp.empty_like(ind_tmp).at[:].set(n)\n",
    "    \n",
    "    ind_tmp = jnp.where(ind_not_in_hist, ind_tmp, sentinels)\n",
    "    \n",
    "    # moves sentinels to end of array -- since n is larger than all other\n",
    "    # elementary vector dimensions\n",
    "    ind_tmp = ind_tmp.sort()\n",
    "    \n",
    "    # we only need the first t elements\n",
    "    ind = ind_tmp[:t]\n",
    "    \n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4276bc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elementary_vector_with_lookup(n, i, ind):\n",
    "    \"\"\"\n",
    "    e_{ind[i]}\n",
    "    \"\"\"\n",
    "    return elementary_vector(n, ind[i])\n",
    "\n",
    "def elementary_vector(n, i):\n",
    "    \"\"\"\n",
    "    e_i\n",
    "    if i == n, then the zero vector is returned\n",
    "    \"\"\"\n",
    "    v = jnp.zeros(n, dtype=float)\n",
    "    v = lax.cond(i == n, lambda: v, lambda: v.at[i].set(1))\n",
    "    return v\n",
    "\n",
    "# Batches i to return a matrix (n, len(i)) with column elementary vectors\n",
    "elementary_vectors_with_lookup = vmap(elementary_vector_with_lookup, in_axes=(None, 0, None), out_axes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ef59733",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "n = 2048\n",
    "t = 256\n",
    "itmax = 5 \n",
    "A = jax.random.normal(key, (n,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b853f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6 s ± 8.08 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def helper():\n",
    "    est, v, w, nmults, nresamples = onenormest(key, A, t, itmax)\n",
    "    est.block_until_ready()\n",
    "\n",
    "helper()\n",
    "\n",
    "%timeit helper()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
